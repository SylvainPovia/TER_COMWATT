# -*- coding: utf-8 -*-
"""Modèle ADAM 06 10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/SylvainPovia/7c88b116bf2ac7d7ec792bd7d682973d/mod-le-adam-06-10.ipynb
"""

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

import os
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.pyplot import imread, imshow, subplots, show

from sklearn.metrics import confusion_matrix,classification_report

import seaborn as sns

## ANCIEN CODE AVEC ZIP

# import pathlib
# from zipfile import ZipFile

os.environ["CUDA_VISIBLE_DEVICES"] = "3"

# file_name = "/content/data.zip"
# with ZipFile(file_name,'r') as zip:
#   zip.extractall()

# A UTILISER SEULEMENT SUR COLAB

from google.colab import drive
drive.mount('/content/drive')

# A UTILISER SEULEMENT SUR COLAB

#Les codes suivants permettent d'instancier la localisation des données et leurs labels
PATH = os.path.join(os.path.dirname('/content/content'), 
                    'drive/My Drive/MASTER 1 MIASHS/TER COMWATT/TER COMWATT/Images labellisées')
                    # Risque de changer selon l'utilisateur
print(PATH)

"""##Données"""

## ANCIEN CODE AVEC ZIP
# PATH = os.path.join(os.path.dirname('/content/content'), 'data')
# print(PATH)

## ON LISTE CHAQUE FOLD
dirs = []
for i in range(0, 7):
    dirs.append(os.path.join(PATH, 'Dossier ' + str(i)))
print(dirs[0])
print(dirs[1])
print(dirs[2])

# On déclare le chemin vers les dossiers
dossier_0 = []
dossier_1 = []
dossier_2 = []
dossier_3 = []
dossier_4 = []
dossier_5 = []
dossier_6 = []
categories = os.listdir(dirs[0])
for i in categories: #Nb de catégories
    dossier_0.append(os.path.join(dirs[0], i))
    dossier_1.append(os.path.join(dirs[1], i))
    dossier_2.append(os.path.join(dirs[2], i))
    dossier_3.append(os.path.join(dirs[3], i))
    dossier_4.append(os.path.join(dirs[4], i))
    dossier_5.append(os.path.join(dirs[5], i))
    dossier_6.append(os.path.join(dirs[6], i))

print(dossier_1[0])
print(dossier_2[1])
print(dossier_3[0])

# On vérifie que le nom des dossiers soient les mêmes
print('Dossier 0 : référence')
print('Dossier 1 :', (sorted(os.listdir(dirs[0]))) == sorted((os.listdir(dirs[1]))))
print('Dossier 2 :', (sorted(os.listdir(dirs[0]))) == sorted((os.listdir(dirs[2]))))
print('Dossier 3 :', (sorted(os.listdir(dirs[0]))) == sorted((os.listdir(dirs[3]))))
print('Dossier 4 :', (sorted(os.listdir(dirs[0]))) == sorted((os.listdir(dirs[4]))))
print('Dossier 5 :', (sorted(os.listdir(dirs[0]))) == sorted((os.listdir(dirs[5]))))
print('Dossier 6 :', (sorted(os.listdir(dirs[0]))) == sorted((os.listdir(dirs[6]))))

#On compte le nombre d'images pour vérifier

total_0 = 0
total_1 = 0
total_2 = 0
total_3 = 0
total_4 = 0
total_5 = 0
total_6 = 0

for i in dossier_0:
    nb = len(os.listdir(i))
    total_0 += nb
    print('total dossier 0 in', '...\''+i[-30:], '\' : ', nb)

for i in dossier_1:
    nb = len(os.listdir(i))
    total_1 += nb
    print('total dossier 1 in', '...\''+i[-30:], '\' : ', nb)

for i in dossier_2:
    nb = len(os.listdir(i))
    total_2 += nb
    print('total dossier 2 in', '...\''+i[-30:], '\' : ', nb)

for i in dossier_3:
    nb = len(os.listdir(i))
    total_3 += nb
    print('total dossier 3 in', '...\''+i[-30:], '\' : ', nb)

for i in dossier_4:
    nb = len(os.listdir(i))
    total_4 += nb
    print('total dossier 4 in', '...\''+i[-30:], '\' : ', nb)

for i in dossier_5:
    nb = len(os.listdir(i))
    total_5 += nb
    print('total dossier 5 in', '...\''+i[-30:], '\' : ', nb)

for i in dossier_6:
    nb = len(os.listdir(i))
    total_6 += nb
    print('total dossier 6 in', '...\''+i[-30:], '\' : ', nb)

print('---')

print("Total images dossier 0 :", total_0)
print("Total images dossier 1 :", total_1)
print("Total images dossier 2 :", total_2)
print("Total images dossier 3 :", total_3)
print("Total images dossier 4 :", total_4)
print("Total images dossier 5 :", total_5)
print("Total images dossier 6 :", total_6)

"""##Modèle

### Préparation du modèle
"""

### ICI CE SONT LES PARAMETRES A CHANGER ###

batch_size = 32
epochs = 8

IMG_HEIGHT = 150
IMG_WIDTH = 150

### ON PARAMETRE LE MODELE

def createModel():
    '''
    Cette fonction permet d'instancier le modèle
    '''
    model = Sequential([
        Conv2D(16, kernel_size=5, strides=2, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
        MaxPooling2D(),
        Conv2D(32, kernel_size=5, strides=2, padding='same', activation='relu'),
        MaxPooling2D(),
        Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu'),
        MaxPooling2D(),
        Flatten(),
        Dense(128, activation='relu'),
        Dense(len(categories), activation='softmax')
    ])

    model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
    
    return model

## ON LE COMPILE

model = createModel()
model.summary()

"""### Entrainement du modèle"""

### CETTE FONCTION PERMET DE FUSIONNER PLUSIEURS DOSSIERS
### (Me demandez pas j'ai trouvé ça sur internet) (Ne marche pas)
def doubleGenerator(generator1,generator2,generator3,generator4,generator5,generator6):
    while True:
        for (x1,y1),(x2,y2),(x3,y3),(x4,y4),(x5,y5),(x6,y6) in zip(generator1,generator2,generator3,generator4,generator5,generator6):
            listey = [y1, y2, y3, y4, y5, y6]
            y = [item for sublist in listey for item in sublist]
            listex = [x1, x2, x3, x4, x5, x6]
            x = [item for sublist in listex for item in sublist]
            yield (x,y)


### PARAMETRES DE DATA AUGMENTAION
datagen = ImageDataGenerator(zoom_range=[1,1.50],            #Zoom
                             rotation_range=20,              #Rotation
                             width_shift_range=[-20,20],     #Décalage vertical4
                             height_shift_range=[-20,20],    #Décalage horizontal
                             brightness_range=[0.7,1.1],     #Luminosité
                             horizontal_flip=True,           #Miroir
                             rescale= 1./255
                             )

## On prépare des variables pour stocker l'historique de l'accuracy et la loss
train_acc_hist = []
val_acc_hist = []
train_loss_hist = []
val_loss_hist = []

## On prépare une variable pour donner l'ordre des dossiers de validation
orderval = [2, 3, 4, 5, 6, 0, 1]

### POUR CHAQUE FOLD, ON ENTRAINE LE MODELE 
### (chaque fois on utilise un batch d'images aléatorisées par la data augmentation)
for iterateur in range(0,(7*10)):
    i = iterateur%7
    print('--------- BOUCLE :', iterateur+1, '---------')
    train_data = []

    train_data = datagen.flow_from_directory(batch_size=batch_size,
                                             directory=dirs[i],
                                             target_size=(IMG_HEIGHT, IMG_WIDTH),
                                             class_mode='categorical',
                                             shuffle=False)
    
    val_data_gen = datagen.flow_from_directory(batch_size=batch_size,
                                               directory=dirs[orderval[i]],
                                               shuffle=False,
                                               target_size=(IMG_HEIGHT, IMG_WIDTH),
                                               class_mode='categorical')
    
    # On fusionne les dossiers du train.
    # trainbatch = doubleGenerator(train_data[0],train_data[1],
    #                              train_data[2],train_data[3],
    #                              train_data[4],train_data[5])
    
    # On lance le modèle
    history = model.fit_generator(
        train_data,
        steps_per_epoch= (total_0 * 6) // batch_size,
        epochs=epochs,
        validation_data=val_data_gen,
        validation_steps= total_0 // batch_size
    )

    # On stocke l'historique de l'accuracy et la perte
    train_acc_hist.append(history.history['acc'])
    val_acc_hist.append(history.history['val_acc'])
    train_loss_hist.append(history.history['loss'])
    val_loss_hist.append(history.history['val_loss'])


model.save("/content/drive/My Drive/MASTER 1 MIASHS/TER COMWATT/TER COMWATT/model_7fois10.h5")
print("Saved model to disk")

"""##Metrics"""

#On plot l'accuracy globale

train_acc_hist_flat = [item for sublist in train_acc_hist for item in sublist]
val_acc_hist_flat = [item for sublist in val_acc_hist for item in sublist]

plt.figure(figsize=(12, 6))  
 
plt.plot(train_acc_hist_flat)  
plt.plot(val_acc_hist_flat)  
plt.title('model accuracy historique')  
plt.ylabel('accuracy')  
plt.xlabel('epoch')  
plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')  
plt.ylim(0,1)
plt.grid(color='lightgrey')
plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])

plt.show()

#On plot l'accuracy de la dernière boucle

plt.figure(figsize=(12, 6))  
 
plt.plot(history.history['acc'])  
plt.plot(history.history['val_acc'])  
plt.title('model accuracy derniere boucle')  
plt.ylabel('accuracy')  
plt.xlabel('epoch')  
plt.legend(['Training accuracy', 'Validation accuracy'], loc='lower right')  
plt.ylim(0,1)
plt.grid(color='lightgrey')
plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])

plt.show()

avgacc = history.history['val_acc'][3]
print("Dernière Accuray = " + str(avgacc))

#On plot la perte globale

train_loss_hist_flat = [item for sublist in train_loss_hist for item in sublist]
val_loss_hist_flat = [item for sublist in val_loss_hist for item in sublist]

plt.figure(figsize=(12, 6))  
 
plt.plot(train_loss_hist_flat)  
plt.plot(val_loss_hist_flat)  
plt.title('model loss historique')  
plt.ylabel('accuracy')  
plt.xlabel('epoch')  
plt.legend(['Training loss', 'Validation loss'], loc='lower right')
plt.grid(color='lightgrey')

plt.show()

## On prépare la matrice de confusion
datagenconf = ImageDataGenerator(rescale= 1./255)

truc = []
tc = []
yp = []
for i in range(0,7):
    if(i!=4 and i!=5):
        trainconf = datagenconf.flow_from_directory(batch_size=batch_size,
                                                        directory=dirs[i],
                                                        shuffle=False,
                                                        target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                        class_mode='categorical')

        predictions = model.predict_generator(trainconf,  total_0 // batch_size+1)

        y_pred = np.argmax(predictions, axis=1)

        true_classes = trainconf.classes

        class_labels = list(trainconf.class_indices.keys())

        tc.append(true_classes)
        yp.append(y_pred)
        truc.append(confusion_matrix(trainconf.classes, y_pred))

truc2 = truc[0]+truc[1]+truc[2]+truc[3]+truc[4]

## On plot la matrice de confusion
sns.set()
ax = sns.heatmap(truc2, 
                 cmap="YlGnBu", 
                 xticklabels=class_labels, yticklabels=class_labels)

## On print le classification report 

true_classes = [item for sublist in tc for item in sublist]
y_pred = [item for sublist in yp for item in sublist]
print(classification_report(true_classes, y_pred, target_names=class_labels))

"""##Enregistement du modèle"""

model.save("/content/drive/My Drive/MASTER 1 MIASHS/TER COMWATT/TER COMWATT/modele_7fois10.h5")
print("Saved model to disk")

"""##Tests manuels"""

## Réimport du modèle
from tensorflow.keras.models import load_model
 
modelcharge = load_model('modele_05_03.h5')
modelcharge.summary()

from keras.preprocessing import image
from keras.applications.resnet50 import preprocess_input, decode_predictions

img_path = '/content/top1.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top1:', preds)

img_path = '/content/top2.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top2:', preds)

img_path = '/content/top3.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top3:', preds)

img_path = '/content/hub1.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub1:', preds)

img_path = '/content/hub2.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub2:', preds)

img_path = '/content/hub3.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub3:', preds)

img_path = '/content/top1.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top1:', preds)

img_path = '/content/top4.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top4:', preds)

img_path = '/content/top5.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top5:', preds)

img_path = '/content/top6.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top6:', preds)

img_path = '/content/top7.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top7:', preds)

img_path = '/content/top8.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top8:', preds)

img_path = '/content/top9.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top9:', preds)

img_path = '/content/top10.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted top10:', preds)

img_path = '/content/hub4.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub4:', preds)

img_path = '/content/hub5.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub5:', preds)

img_path = '/content/hub6.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub6:', preds)

img_path = '/content/hub7.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub7:', preds)

img_path = '/content/hub8.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub8:', preds)

img_path = '/content/hub9.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub9:', preds)

img_path = '/content/hub10.jpg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
preds = modelcharge.predict(x)

print('Predicted hub10:', preds)